### BERT (English only)

## Abstract

We developed an NLP-based spam classifier through a transfer learning approach, by fine-tuning a pre-trained English DistilBERT model on the Zenodo dataset for text classification.

## Results

| Training Time | Prediction Time | Accuracy | F1-Score |
|---------------|-----------------|----------|----------|
| 1h02          | 0.005s          | 98.759   | 98.600   |

All computation and time measurement were made using an NVIDIA RTX A5000.
