# BERT (All languages)

## Abstract

We developed an NLP-based spam classifier through a transfer learning approach, by fine-tuning a pre-trained multilingual DistilBERT model on the Zenodo dataset for text classification.

## Results

| Training Time | Prediction Time | Accuracy | F1-Score |
|---------------|-----------------|----------|----------|
| 1h09          | 0.005           | 98.814   | 98.778   |

All computation and time measurement were made using an NVIDIA RTX A5000.
